{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Functions and import"
      ],
      "metadata": {
        "id": "4VTepI3-TzkW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ch4Gb0qrPFS2"
      },
      "outputs": [],
      "source": [
        "pip install FlowCytometryTools\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from FlowCytometryTools import FCMeasurement\n",
        "import warnings\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def summorize_fcs(meta, data_path):\n",
        "    '''\n",
        "    Function that writes medians of each channel into a file\n",
        "    :param meta: pandas dataframe with metadata with the following columns: \n",
        "        file_name, sample_id, condition, patient_id. See example of the metadata table below\n",
        "    \n",
        "    :param data_path: path to .fsc files\n",
        "    \n",
        "    ** Windows Users **\n",
        " \n",
        "    Windows uses the backslash character (‘\\’) for paths. However, the backslash character\n",
        "    is a special character in python that is used for formatting strings. \n",
        "    In order to specify paths correctly, you must precede the path with the character ‘r’.\n",
        " \n",
        "    Good:\n",
        " \n",
        "    >>> data_path=r'C:\\data\\'\n",
        "    Bad:\n",
        " \n",
        "    >>> data_path='C:\\data\\'\n",
        "    \n",
        "    \n",
        "    :returns: 1) dataframe markers by samples\n",
        "    2) dictionary with markers as keys and a median values for healthy and patients\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    files = list(meta.file_name)\n",
        "    status = list(meta.condition)\n",
        "    samp = list(meta.sample_id)\n",
        "    #open the first file to retrieve the order of markers\n",
        "    sample = FCMeasurement(ID='Sample', datafile=data_path +files[0])\n",
        "    dat1 = sample.data\n",
        "    genes = dat1.columns\n",
        "    genes = [x.split(\"_\")[0] for x in genes]\n",
        " \n",
        "    # matrix with medians for each marker and each sample\n",
        "    medians_full = np.zeros((len(genes), len(samp)))\n",
        "    # dictionary with medians for each sample and each condition\n",
        "    medians_cond = dict()\n",
        " \n",
        "    # file processing is performed per marker to avoid loading too much data into memory\n",
        "    for i in range(len(genes)):\n",
        "        gene = genes[i]\n",
        "        old = 0\n",
        "        for j in range(len(files)):\n",
        "            st = status[j]\n",
        "            file = files[j]\n",
        "            gr = samp[j]\n",
        "            sample = FCMeasurement(ID='Sample', datafile=data_path +file)\n",
        "            dat1 = sample.data\n",
        "            gs = dat1.columns\n",
        "            genes_new = [x.split(\"_\")[0] for x in gs]\n",
        "            dat1.columns = genes_new\n",
        "            new_dat = dat1[[gene]]\n",
        "            new_dat.columns = [\"expression\"]\n",
        "            new_dat[\"group\"] = [gr]*dat1.shape[0]\n",
        "            new_dat[\"antibody\"] = [gene]*dat1.shape[0]\n",
        "            new_dat[\"status\"] = [st]*dat1.shape[0]\n",
        "            new_dat.index = np.arange(old,dat1.shape[0]+old)\n",
        "            old = dat1.shape[0] + old\n",
        "            if j == 0:\n",
        "                all_dat = new_dat.copy()\n",
        "            else:    \n",
        "                all_dat = pd.concat([all_dat, new_dat])\n",
        "        #data transformation\n",
        "        all_dat.expression = np.arcsinh(all_dat.expression/5)    \n",
        "        #medians for healthy and patients\n",
        "        hp = all_dat['expression'][all_dat['status'] == 'healthy']\n",
        "        cp = all_dat['expression'][all_dat['status'] == 'patient']\n",
        "        medians_cond[gene] = [np.median(hp), np.median(cp)]\n",
        "        #medians for each sample\n",
        "        for j in range(len(samp)):\n",
        "            s = samp[j]\n",
        "            condition = (all_dat['group'] == s) \n",
        "            vals = all_dat['expression'][condition]\n",
        "            medians_full[i,j] = np.median(vals)\n",
        "    medians_full = pd.DataFrame(medians_full, index = genes, columns = samp)\n",
        "    return(medians_full, medians_cond)\n",
        " \n",
        " \n",
        "def pv_estimate(dat, markers, model):\n",
        "    '''\n",
        "    Computes p-values based on LMM and then performs FDR correction\n",
        "    :param dat: pandas dataframe\n",
        "    :param markers: a list of markers to test\n",
        "    :param model: a string with model description\n",
        "    '''\n",
        "    pvs = []\n",
        "    for m in markers:\n",
        "        d = dat[dat.marker == m]\n",
        "        md = smf.mixedlm(model,d ,\n",
        "                     groups=d[\"samples\"])\n",
        "        try:\n",
        "            mdf = md.fit()\n",
        " \n",
        "            pvs.append((m,mdf.pvalues[1]))\n",
        "        except np.linalg.LinAlgError:\n",
        "            pvs.append((m,np.nan))\n",
        "    # for correction we save only those p-values that were actually computed and did not crash due to 0 variance\n",
        "    ms = []\n",
        "    ps = []\n",
        "    for g,p in pvs:\n",
        "        if not np.isnan(p):\n",
        "            ps.append(p)\n",
        "            ms.append(g)\n",
        "    #FDR correction\n",
        "    _, new_pv = sm.stats.fdrcorrection(ps, alpha=0.05, method='indep', is_sorted=False)\n",
        "    result = dict()\n",
        "    for i in range(len(new_pv)):\n",
        "        result[ms[i]] = new_pv[i]\n",
        "    return(result)"
      ],
      "metadata": {
        "id": "ESFC_xQKT3jO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading and summorizing data"
      ],
      "metadata": {
        "id": "E-EjyK8hUVHm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Not activated data"
      ],
      "metadata": {
        "id": "9tMz14vBlP7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "meta_na = pd.read_excel(\"/content/meta_na.xlsx\" , sheet_name=\"Tabelle1\")\n",
        "display(meta_na)"
      ],
      "metadata": {
        "id": "YCTVsquKUVPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create folder named: files_na\n",
        "files = \"/content/files_na/\"\n",
        "\n",
        "medians_full_na, medians_cond_na = summorize_fcs(meta_na, files)\n"
      ],
      "metadata": {
        "id": "xeueiSXhU3KN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "medians_full_na.head()"
      ],
      "metadata": {
        "id": "HEMFC80MWIQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "medians_full_na"
      ],
      "metadata": {
        "id": "ihxcx9BYKc1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Activated samples"
      ],
      "metadata": {
        "id": "-DcZKJLrWO1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "meta_act = pd.read_excel(\"/content/meta_act.xlsx\", sheet_name=\"Sheet1\")\n",
        "display(meta_act)"
      ],
      "metadata": {
        "id": "R1Nn7Va6WIYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = \"/content/files_a/\"\n",
        "medians_full_act, medians_cond_act = summorize_fcs(meta_act, files)"
      ],
      "metadata": {
        "id": "0VPtwlUTXdci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "medians_full_act.head()"
      ],
      "metadata": {
        "id": "F4B9jcKIXjrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "medians_full_act"
      ],
      "metadata": {
        "id": "FJizKEU0t8ZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concatinating both datasets together for further analysis\n"
      ],
      "metadata": {
        "id": "IUdOMjIKYCzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "meta = pd.concat([meta_na,meta_act], ignore_index=True)\n",
        "markers = medians_full_na.index\n",
        "samples = medians_full_na.columns\n",
        "conditions = [list(meta_na.condition[meta_na.sample_id == x])[0] for x in samples]\n",
        "\n",
        "last_i = 0\n",
        "for i in range(len(markers)):\n",
        "    m = markers[i]\n",
        "    dat1 = medians_full_na.loc[[m]].T\n",
        "    dat1.columns = [\"expression\"]\n",
        "    dat1[\"samples\"] = dat1.index\n",
        "    dat1.index= np.arange(last_i,dat1.shape[0]+last_i)\n",
        "    last_i = dat1.shape[0] +last_i\n",
        "    dat1[\"marker\"] = [m]*dat1.shape[0]\n",
        "    dat1[\"condition\"] = conditions\n",
        "    dat1[\"type\"] = [\"not activated\"]*dat1.shape[0]\n",
        "    if i == 0:\n",
        "        dat = dat1\n",
        "    else:\n",
        "        dat = pd.concat([dat,dat1])\n",
        "\n",
        "markers = medians_full_act.index\n",
        "samples = medians_full_act.columns\n",
        "conditions = [list(meta_act.condition[meta_act.sample_id == x])[0] for x in samples]        \n",
        "for i in range(len(markers)):\n",
        "    m = markers[i]\n",
        "    dat1 = medians_full_act.loc[[m]].T\n",
        "    dat1.columns = [\"expression\"]\n",
        "    dat1[\"samples\"] = dat1.index\n",
        "    dat1.index= np.arange(last_i,dat1.shape[0]+last_i)\n",
        "    last_i = dat1.shape[0] +last_i\n",
        "    dat1[\"marker\"] = [m]*dat1.shape[0]\n",
        "    dat1[\"condition\"] = conditions\n",
        "    dat1[\"type\"] = [\"activated\"]*dat1.shape[0]\n",
        "\n",
        "    dat = pd.concat([dat,dat1])"
      ],
      "metadata": {
        "id": "BfyzJQYLYIM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Activation slope ananlysis"
      ],
      "metadata": {
        "id": "kD7SiyfDZdTv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set activation marker and plot dimensions"
      ],
      "metadata": {
        "id": "YNF4zM7NWuuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Marker definition\n",
        "dat[\"patient\"] = [x[:-1] for x in dat[\"samples\"]]\n",
        "ylims = {\"CD63\": (0,0.5), \"CD107a\": (-0.5,0.5), \"PAC1\": (0, 2), \"CD62P\": (0, 2), \"CD154\": (-0.5,0.5)}\n",
        "\n",
        "act_m = [\"155Gd\", \"150Nd\", \"151Eu\", \"161Dy\", \"168Er\"]\n",
        "\n",
        "panel = list(set(markers).difference(set(act_m)))"
      ],
      "metadata": {
        "id": "C_E-ZNbGZfo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Slope plotting"
      ],
      "metadata": {
        "id": "5BsQfTQ2Zm0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datMP = dat\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "fig = plt.figure(figsize=(14, 9))\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "plt.rc('font', size=12)  # controls default text sizes\n",
        "plt.rc('axes', titlesize=12)  # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=12)  # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=12)  # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=12)  # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=12)\n",
        "datTB = datMP\n",
        "\n",
        "patients = list(set(datTB))\n",
        "colors = ['#9AB8C8', '#DBA794']\n",
        "\n",
        "for i in range(len(act_m)):\n",
        "    ax = fig.add_subplot(3, 5, i+1)\n",
        "    m= act_m[i]\n",
        "    d1 = list(datTB[(datTB.marker == m)&(datTB.condition == \"baseline\")][\"expression\"])\n",
        "    d2 = list(datTB[(datTB.marker == m)&(datTB.condition == \"stimulated\")][\"expression\"])\n",
        "    display(d1)\n",
        "    display(d2)\n",
        "  #plot scatter for each marker\n",
        "    s1 = ax.scatter(np.ones(len(d1)),d1, c = \"#c89ab8\", alpha = 0.8)\n",
        "    s2 = ax.scatter(np.ones(len(d1))*2,d2, c = \"#c89ab8\", alpha = 0.8)\n",
        "\n",
        " # compute the slope\n",
        "    d = datTB[(datTB.marker == m) ]\n",
        "    #display(d)\n",
        "    md = smf.mixedlm(\"expression ~ type\",d, groups=d[\"condition\"]) \n",
        "    mdf = md.fit()\n",
        "  \n",
        "  # print the slope in the plot title\n",
        "    ax.set_title(\"{0}: slope {1}\".format(m, np.round(np.abs(list(mdf.params)[1]),2))) \n",
        "    display(mdf.params)\n",
        "  # make y lable for the most left plot\n",
        "    if i == 0:\n",
        "        ax.set_ylabel('Median expression')\n",
        "  \n",
        "  # for each pair of patients plot a line from not activated sample to activated\n",
        "    for p in patients:\n",
        "      p1 = list(datTB[(datTB.marker == m)&(datTB.condition == \"baseline\")][\"expression\"])[0]\n",
        "      p2 = list(datTB[(datTB.marker == m)&(datTB.condition == \"stimulated\")][\"expression\"])[0]\n",
        "      plt.plot([1,2],[p1,p2], c = \"black\", linestyle = \"--\", alpha = 0.3)\n",
        "    \n",
        "   \n",
        "\n",
        "    # plot the regression fit\n",
        "    plt.sca(ax)\n",
        "    plt.xticks([1,2], [' ', ' '])\n",
        "    xs = [1,0]\n",
        "    b0 = mdf.params[0]\n",
        "    b1 = mdf.params[1]\n",
        "    ys = [b0 + b1*x for x in xs]\n",
        "    #ys = [0,0.8]  # use for scale changes\n",
        "    plt.plot(np.array(ax.get_xlim()),ys, c = '#c89ab8', linestyle = \"-\", alpha = 0.8, linewidth=7) #9AB8C8 old color\n",
        "    plt.xticks([1,2], ['baseline', 'stimulated'])\n",
        "    try:\n",
        "      plt.ylim(ylims[m])\n",
        "    except:\n",
        "      KeyError"
      ],
      "metadata": {
        "id": "aP9IA7_egfGU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}